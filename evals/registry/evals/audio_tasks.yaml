audio-transcribe:
  id: audio-transcribe.test.v1
  metrics: [accuracy]
audio-transcribe.validation.v1:
  class: evals.elsuite.audio.eval:Transcribe
  args:
    dataset: hf://openslr/librispeech_asr?split=validation.clean
audio-transcribe.test.v1:
  class: evals.elsuite.audio.eval:Transcribe
  args:
    dataset: hf://openslr/librispeech_asr?split=test.clean

audio-boolq:
  id: audio-boolq.validation.v1
  metrics: [accuracy]
audio-boolq.dev.v1:
  class: evals.elsuite.audio.eval:SpokenBoolQ
  args:
    dataset: hf://fixie-ai/boolq-audio?split=train
audio-boolq.validation.v1:
  class: evals.elsuite.audio.eval:SpokenBoolQ
  args:
    dataset: hf://fixie-ai/boolq-audio?split=validation

audio-ser:
  id: audio-ser.validation.v1
  metrics: [accuracy]
audio-ser.dev.v1:
  class: evals.elsuite.audio.eval:SpokenER
  args:
    dataset: hf://Zahra99/IEMOCAP_Audio?split=session1
audio-ser.validation.v1:
  class: evals.elsuite.audio.eval:SpokenER
  args:
    dataset: hf://Zahra99/IEMOCAP_Audio?split=session5

audio-sqa:
  id: audio-sqa.validation.v1
  metrics: [accuracy]
audio-sqa.dev.v1:
  class: evals.elsuite.audio.eval:SpokenQA
  args:
    dataset: hf://WillHeld/HeySQuAD_distill?split=train
    eval_completion_fn: gpt-4o
    modelgraded_spec: closedqa
    modelgraded_spec_args:
      criteria: "correctness: Is the answer correct?"
audio-sqa.validation.v1:
  class: evals.elsuite.audio.eval:SpokenQA
  args:
    dataset: hf://WillHeld/HeySQuAD_distill?split=validation
    eval_completion_fn: gpt-4o
    modelgraded_spec: closedqa
    modelgraded_spec_args:
      criteria: "correctness: Is the answer correct?"

audio-tools:
  id: audio-tools.validation.v1
  metrics: [accuracy]
audio-tools.dev.v1:
  class: evals.elsuite.audio.eval:SpokenTools
  args:
    dataset: hf://fixie-ai/tools-audio?split=train
audio-tools.validation.v1:
  class: evals.elsuite.audio.eval:SpokenTools
  args:
    dataset: hf://fixie-ai/tools-audio?split=validation

audio-swuggy:
  id: audio-swuggy.validation.v1
  metrics: [accuracy]
audio-swuggy.validation.v1:
  class: evals.elsuite.audio.eval:SpokenCompare
  args:
    dataset: hf://DynamicSuperb/NonceWordDetection_sWUGGY?split=test

audio-sblimp:
  id: audio-sblimp.validation.v1
  metrics: [accuracy]
audio-sblimp.validation.v1:
  class: evals.elsuite.audio.eval:SpokenCompare
  args:
    dataset: hf://DynamicSuperb/SentenceGrammarAcceptability_sBLIMP?split=test

# Text-only versions

transcript-transcribe:
  id: transcript-transcribe.test.v1
  metrics: [accuracy]
transcript-transcribe.validation.v1:
  class: evals.elsuite.audio.eval:Transcribe
  args:
    dataset: hf://openslr/librispeech_asr?split=validation.clean
transcript-transcribe.test.v1:
  class: evals.elsuite.audio.eval:Transcribe
  args:
    dataset: hf://openslr/librispeech_asr?split=test.clean
    text_only: true

transcript-boolq:
  id: transcript-boolq.validation.v1
  metrics: [accuracy]
transcript-boolq.dev.v1:
  class: evals.elsuite.audio.eval:SpokenBoolQ
  args:
    dataset: hf://fixie-ai/boolq-audio?split=train
    text_only: true
transcript-boolq.validation.v1:
  class: evals.elsuite.audio.eval:SpokenBoolQ
  args:
    dataset: hf://fixie-ai/boolq-audio?split=validation
    text_only: true

transcript-ser:
  id: transcript-ser.validation.v1
  metrics: [accuracy]
transcript-ser.dev.v1:
  class: evals.elsuite.audio.eval:SpokenER
  args:
    dataset: hf://Zahra99/IEMOCAP_Audio?split=session1
    text_only: true
transcript-ser.validation.v1:
  class: evals.elsuite.audio.eval:SpokenER
  args:
    dataset: hf://Zahra99/IEMOCAP_Audio?split=session5
    text_only: true

transcript-sqa:
  id: transcript-sqa.validation.v1
  metrics: [accuracy]
transcript-sqa.dev.v1:
  class: evals.elsuite.audio.eval:SpokenQA
  args:
    dataset: hf://WillHeld/HeySQuAD_distill?split=train
    eval_completion_fn: gpt-4o
    modelgraded_spec: closedqa
    modelgraded_spec_args:
      criteria: "correctness: Is the answer correct?"
transcript-sqa.validation.v1:
  class: evals.elsuite.audio.eval:SpokenQA
  args:
    dataset: hf://WillHeld/HeySQuAD_distill?split=validation
    text_only: true
    eval_completion_fn: gpt-4o
    modelgraded_spec: closedqa
    modelgraded_spec_args:
      criteria: "correctness: Is the answer correct?"

transcript-tools:
  id: transcript-tools.validation.v1
  metrics: [accuracy]
transcript-tools.dev.v1:
  class: evals.elsuite.audio.eval:SpokenTools
  args:
    dataset: hf://fixie-ai/tools-audio?split=train
transcript-tools.validation.v1:
  class: evals.elsuite.audio.eval:SpokenTools
  args:
    dataset: hf://fixie-ai/tools-audio?split=validation
    text_only: true
